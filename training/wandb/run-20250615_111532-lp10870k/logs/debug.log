2025-06-15 11:15:32,988 INFO    Thread-47 :40186 [wandb_setup.py:_flush():81] Current SDK version is 0.20.1
2025-06-15 11:15:32,988 INFO    Thread-47 :40186 [wandb_setup.py:_flush():81] Configure stats pid to 40186
2025-06-15 11:15:32,988 INFO    Thread-47 :40186 [wandb_setup.py:_flush():81] Loading settings from /home/parastoo/.config/wandb/settings
2025-06-15 11:15:32,988 INFO    Thread-47 :40186 [wandb_setup.py:_flush():81] Loading settings from /home/parastoo/Desktop/new1/RL/training/wandb/settings
2025-06-15 11:15:32,988 INFO    Thread-47 :40186 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-06-15 11:15:32,988 INFO    Thread-47 :40186 [wandb_init.py:setup_run_log_directory():703] Logging user logs to /home/parastoo/Desktop/new1/RL/training/wandb/run-20250615_111532-lp10870k/logs/debug.log
2025-06-15 11:15:32,988 INFO    Thread-47 :40186 [wandb_init.py:setup_run_log_directory():704] Logging internal logs to /home/parastoo/Desktop/new1/RL/training/wandb/run-20250615_111532-lp10870k/logs/debug-internal.log
2025-06-15 11:15:32,988 INFO    Thread-47 :40186 [wandb_init.py:init():831] calling init triggers
2025-06-15 11:15:32,988 INFO    Thread-47 :40186 [wandb_init.py:init():836] wandb.init called with sweep_config: {'batch_size': 57, 'gae_lambda': 0.8917574810135837, 'gamma': 0.9134442638976354, 'learning_rate': 0.0006228885729975058, 'n_epochs': 17}
config: {'method': 'random', 'metric': {'name': 'mean_mean_reward', 'goal': 'maximize'}, 'parameters': {'learning_rate': {'min': 3e-05, 'max': 0.003}, 'gamma': {'min': 0.9, 'max': 0.9999}, 'batch_size': {'min': 32, 'max': 128}, 'n_epochs': {'min': 5, 'max': 20}, 'gae_lambda': {'min': 0.85, 'max': 0.999}}, '_wandb': {}}
2025-06-15 11:15:32,988 INFO    Thread-47 :40186 [wandb_init.py:init():872] starting backend
2025-06-15 11:15:33,235 INFO    Thread-47 :40186 [wandb_init.py:init():875] sending inform_init request
2025-06-15 11:15:33,236 INFO    Thread-47 :40186 [wandb_init.py:init():883] backend started and connected
2025-06-15 11:15:33,237 INFO    Thread-47 :40186 [wandb_run.py:_config_callback():1358] config_cb None None {'batch_size': 57, 'gae_lambda': 0.8917574810135837, 'gamma': 0.9134442638976354, 'learning_rate': 0.0006228885729975058, 'n_epochs': 17}
2025-06-15 11:15:33,239 INFO    Thread-47 :40186 [wandb_init.py:init():956] updated telemetry
2025-06-15 11:15:33,289 INFO    Thread-47 :40186 [wandb_init.py:init():980] communicating run to backend with 90.0 second timeout
2025-06-15 11:15:34,089 INFO    Thread-47 :40186 [wandb_init.py:init():1032] starting run threads in backend
2025-06-15 11:15:34,135 INFO    Thread-47 :40186 [wandb_run.py:_console_start():2453] atexit reg
2025-06-15 11:15:34,135 INFO    Thread-47 :40186 [wandb_run.py:_redirect():2301] redirect: wrap_raw
2025-06-15 11:15:34,135 INFO    Thread-47 :40186 [wandb_run.py:_redirect():2370] Wrapping output streams.
2025-06-15 11:15:34,136 INFO    Thread-47 :40186 [wandb_run.py:_redirect():2393] Redirects installed.
2025-06-15 11:15:34,136 INFO    Thread-47 :40186 [wandb_init.py:init():1078] run started, returning control to user process
2025-06-15 11:40:30,920 INFO    Thread-47 :40186 [wandb_run.py:_finish():2219] finishing run parastoohashemi78-politecnico-di-torino/ppo_sweep_ss/lp10870k
2025-06-15 11:40:30,920 INFO    Thread-47 :40186 [wandb_run.py:_atexit_cleanup():2418] got exitcode: 0
2025-06-15 11:40:30,920 INFO    Thread-47 :40186 [wandb_run.py:_restore():2400] restore
2025-06-15 11:40:30,921 INFO    Thread-47 :40186 [wandb_run.py:_restore():2406] restore done
2025-06-15 11:40:31,854 INFO    Thread-47 :40186 [wandb_run.py:_footer_history_summary_info():4000] rendering history
2025-06-15 11:40:31,854 INFO    Thread-47 :40186 [wandb_run.py:_footer_history_summary_info():4032] rendering summary
2025-06-15 11:40:31,854 INFO    Thread-47 :40186 [wandb_run.py:_footer_sync_info():3961] logging synced files
