2025-06-15 07:28:06,751 INFO    Thread-14 :40186 [wandb_setup.py:_flush():81] Current SDK version is 0.20.1
2025-06-15 07:28:06,751 INFO    Thread-14 :40186 [wandb_setup.py:_flush():81] Configure stats pid to 40186
2025-06-15 07:28:06,751 INFO    Thread-14 :40186 [wandb_setup.py:_flush():81] Loading settings from /home/parastoo/.config/wandb/settings
2025-06-15 07:28:06,751 INFO    Thread-14 :40186 [wandb_setup.py:_flush():81] Loading settings from /home/parastoo/Desktop/new1/RL/training/wandb/settings
2025-06-15 07:28:06,751 INFO    Thread-14 :40186 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-06-15 07:28:06,751 INFO    Thread-14 :40186 [wandb_init.py:setup_run_log_directory():703] Logging user logs to /home/parastoo/Desktop/new1/RL/training/wandb/run-20250615_072806-2gdfhium/logs/debug.log
2025-06-15 07:28:06,751 INFO    Thread-14 :40186 [wandb_init.py:setup_run_log_directory():704] Logging internal logs to /home/parastoo/Desktop/new1/RL/training/wandb/run-20250615_072806-2gdfhium/logs/debug-internal.log
2025-06-15 07:28:06,751 INFO    Thread-14 :40186 [wandb_init.py:init():831] calling init triggers
2025-06-15 07:28:06,751 INFO    Thread-14 :40186 [wandb_init.py:init():836] wandb.init called with sweep_config: {'batch_size': 118, 'gae_lambda': 0.874693544013463, 'gamma': 0.913073760094834, 'learning_rate': 0.0018281185222174328, 'n_epochs': 17}
config: {'method': 'random', 'metric': {'name': 'mean_mean_reward', 'goal': 'maximize'}, 'parameters': {'learning_rate': {'min': 3e-05, 'max': 0.003}, 'gamma': {'min': 0.9, 'max': 0.9999}, 'batch_size': {'min': 32, 'max': 128}, 'n_epochs': {'min': 5, 'max': 20}, 'gae_lambda': {'min': 0.85, 'max': 0.999}}, '_wandb': {}}
2025-06-15 07:28:06,751 INFO    Thread-14 :40186 [wandb_init.py:init():872] starting backend
2025-06-15 07:28:06,998 INFO    Thread-14 :40186 [wandb_init.py:init():875] sending inform_init request
2025-06-15 07:28:06,999 INFO    Thread-14 :40186 [wandb_init.py:init():883] backend started and connected
2025-06-15 07:28:07,000 INFO    Thread-14 :40186 [wandb_run.py:_config_callback():1358] config_cb None None {'batch_size': 118, 'gae_lambda': 0.874693544013463, 'gamma': 0.913073760094834, 'learning_rate': 0.0018281185222174328, 'n_epochs': 17}
2025-06-15 07:28:07,002 INFO    Thread-14 :40186 [wandb_init.py:init():956] updated telemetry
2025-06-15 07:28:07,050 INFO    Thread-14 :40186 [wandb_init.py:init():980] communicating run to backend with 90.0 second timeout
2025-06-15 07:28:07,625 INFO    Thread-14 :40186 [wandb_init.py:init():1032] starting run threads in backend
2025-06-15 07:28:07,671 INFO    Thread-14 :40186 [wandb_run.py:_console_start():2453] atexit reg
2025-06-15 07:28:07,671 INFO    Thread-14 :40186 [wandb_run.py:_redirect():2301] redirect: wrap_raw
2025-06-15 07:28:07,671 INFO    Thread-14 :40186 [wandb_run.py:_redirect():2370] Wrapping output streams.
2025-06-15 07:28:07,671 INFO    Thread-14 :40186 [wandb_run.py:_redirect():2393] Redirects installed.
2025-06-15 07:28:07,671 INFO    Thread-14 :40186 [wandb_init.py:init():1078] run started, returning control to user process
2025-06-15 07:47:38,144 INFO    Thread-14 :40186 [wandb_run.py:_finish():2219] finishing run parastoohashemi78-politecnico-di-torino/ppo_sweep_ss/2gdfhium
2025-06-15 07:47:38,145 INFO    Thread-14 :40186 [wandb_run.py:_atexit_cleanup():2418] got exitcode: 0
2025-06-15 07:47:38,145 INFO    Thread-14 :40186 [wandb_run.py:_restore():2400] restore
2025-06-15 07:47:38,145 INFO    Thread-14 :40186 [wandb_run.py:_restore():2406] restore done
2025-06-15 07:47:39,465 INFO    Thread-14 :40186 [wandb_run.py:_footer_history_summary_info():4000] rendering history
2025-06-15 07:47:39,465 INFO    Thread-14 :40186 [wandb_run.py:_footer_history_summary_info():4032] rendering summary
2025-06-15 07:47:39,466 INFO    Thread-14 :40186 [wandb_run.py:_footer_sync_info():3961] logging synced files
