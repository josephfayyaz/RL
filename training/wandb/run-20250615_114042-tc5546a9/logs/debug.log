2025-06-15 11:40:42,283 INFO    Thread-50 :40186 [wandb_setup.py:_flush():81] Current SDK version is 0.20.1
2025-06-15 11:40:42,283 INFO    Thread-50 :40186 [wandb_setup.py:_flush():81] Configure stats pid to 40186
2025-06-15 11:40:42,283 INFO    Thread-50 :40186 [wandb_setup.py:_flush():81] Loading settings from /home/parastoo/.config/wandb/settings
2025-06-15 11:40:42,283 INFO    Thread-50 :40186 [wandb_setup.py:_flush():81] Loading settings from /home/parastoo/Desktop/new1/RL/training/wandb/settings
2025-06-15 11:40:42,283 INFO    Thread-50 :40186 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-06-15 11:40:42,283 INFO    Thread-50 :40186 [wandb_init.py:setup_run_log_directory():703] Logging user logs to /home/parastoo/Desktop/new1/RL/training/wandb/run-20250615_114042-tc5546a9/logs/debug.log
2025-06-15 11:40:42,283 INFO    Thread-50 :40186 [wandb_init.py:setup_run_log_directory():704] Logging internal logs to /home/parastoo/Desktop/new1/RL/training/wandb/run-20250615_114042-tc5546a9/logs/debug-internal.log
2025-06-15 11:40:42,283 INFO    Thread-50 :40186 [wandb_init.py:init():831] calling init triggers
2025-06-15 11:40:42,283 INFO    Thread-50 :40186 [wandb_init.py:init():836] wandb.init called with sweep_config: {'batch_size': 82, 'gae_lambda': 0.8875150339528106, 'gamma': 0.9006893231405803, 'learning_rate': 0.0018928472648618324, 'n_epochs': 16}
config: {'method': 'random', 'metric': {'name': 'mean_mean_reward', 'goal': 'maximize'}, 'parameters': {'learning_rate': {'min': 3e-05, 'max': 0.003}, 'gamma': {'min': 0.9, 'max': 0.9999}, 'batch_size': {'min': 32, 'max': 128}, 'n_epochs': {'min': 5, 'max': 20}, 'gae_lambda': {'min': 0.85, 'max': 0.999}}, '_wandb': {}}
2025-06-15 11:40:42,283 INFO    Thread-50 :40186 [wandb_init.py:init():872] starting backend
2025-06-15 11:40:42,530 INFO    Thread-50 :40186 [wandb_init.py:init():875] sending inform_init request
2025-06-15 11:40:42,532 INFO    Thread-50 :40186 [wandb_init.py:init():883] backend started and connected
2025-06-15 11:40:42,532 INFO    Thread-50 :40186 [wandb_run.py:_config_callback():1358] config_cb None None {'batch_size': 82, 'gae_lambda': 0.8875150339528106, 'gamma': 0.9006893231405803, 'learning_rate': 0.0018928472648618324, 'n_epochs': 16}
2025-06-15 11:40:42,534 INFO    Thread-50 :40186 [wandb_init.py:init():956] updated telemetry
2025-06-15 11:40:42,584 INFO    Thread-50 :40186 [wandb_init.py:init():980] communicating run to backend with 90.0 second timeout
2025-06-15 11:40:43,036 INFO    Thread-50 :40186 [wandb_init.py:init():1032] starting run threads in backend
2025-06-15 11:40:43,084 INFO    Thread-50 :40186 [wandb_run.py:_console_start():2453] atexit reg
2025-06-15 11:40:43,084 INFO    Thread-50 :40186 [wandb_run.py:_redirect():2301] redirect: wrap_raw
2025-06-15 11:40:43,084 INFO    Thread-50 :40186 [wandb_run.py:_redirect():2370] Wrapping output streams.
2025-06-15 11:40:43,084 INFO    Thread-50 :40186 [wandb_run.py:_redirect():2393] Redirects installed.
2025-06-15 11:40:43,085 INFO    Thread-50 :40186 [wandb_init.py:init():1078] run started, returning control to user process
2025-06-15 12:01:24,168 INFO    Thread-50 :40186 [wandb_run.py:_finish():2219] finishing run parastoohashemi78-politecnico-di-torino/ppo_sweep_ss/tc5546a9
2025-06-15 12:01:24,168 INFO    Thread-50 :40186 [wandb_run.py:_atexit_cleanup():2418] got exitcode: 0
2025-06-15 12:01:24,168 INFO    Thread-50 :40186 [wandb_run.py:_restore():2400] restore
2025-06-15 12:01:24,168 INFO    Thread-50 :40186 [wandb_run.py:_restore():2406] restore done
2025-06-15 12:01:25,130 INFO    Thread-50 :40186 [wandb_run.py:_footer_history_summary_info():4000] rendering history
2025-06-15 12:01:25,131 INFO    Thread-50 :40186 [wandb_run.py:_footer_history_summary_info():4032] rendering summary
2025-06-15 12:01:25,131 INFO    Thread-50 :40186 [wandb_run.py:_footer_sync_info():3961] logging synced files
